---
* during save, deep import models doubling
Commit:
	- get deep_import association distribution
		- DeepImportModel.group( belongs_to_id_field ).select( count( deep_import_id ) ).order( belongs_to_id_field )
	- get and compare association distribution 
		- Model.group( belongs_to_id_field ).select( count( id ) ).order( belongs_to_id_field )
		- is the ordering correct to do this? or should I force a group_by deep_import_belongs_to_id_field

---
deep_import:setup
	- for each model: (generate statements)
		- migration only for existing models:
    		add_column :parents, :deep_import_id, :string
      	add_index :parents, [:deep_import_id, :id], :name => 'di_id_index'
		- migration and model file for deep_import models
class AddDeepImportIdToParents < ActiveRecord::Migration
  def change
    create_table :deep_import_parents do |t|
      t.string :deep_import_id
      t.datetime :parsed_at

		# for each belongs to
      t.string :deep_import_parent_id

      t.timestamps
    end
		# for each belongs to
    add_index :deep_import_children, [:deep_import_id, :deep_import_parent_id], :name => 'di_parent'
  end
end

class DeepImportChild < ActiveRecord::Base
  attr_accessible :deep_import_id, :parsed_at
	# for each belongs_to
	attr_accessible :deep_import_parent_id
end

---
testing:
	- config
	- setup
	- cache
	- commit
				
---
batch id:
- get a process id
- set deep_import_id = "#{process_id}.#{id}"
- commit: scope all queries to this process_id prefix

---
belongs_to:
- to allow:
	- child.other_parent = other_parent
- :before_save:
	- for each /.*_id/ field, if ! self.<non-id>.nil?, set deep import id's accordingly
		- # for each association

---
rake deep_import:setup:
	- detect script/ files
	- run destroy
	- remove both
	- create new ones

---
Config File:
	- Validate: check class names for existence/validity
	- Generate: analyze models with ruby_erd

---
Model Flags:
_preexisting:
	- integer instead of string 
_polymorphic:
